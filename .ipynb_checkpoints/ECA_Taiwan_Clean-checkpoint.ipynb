{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ocr= pd.read_csv('ECA_Taiwan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>ocr_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003c4f0-d60f-11e7-b559-3b0450bb4b8f</td>\n",
       "      <td>DECLASSIFIED\\nAuthority\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007f860-df8b-11e7-9dda-8be1c775c1be</td>\n",
       "      <td>National Advisory Council\\nStDocument No. 236\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000bfbf0-d607-11e7-839a-3da120885759</td>\n",
       "      <td>DECLASSIFIED\\nAuthority. escal-\\nthe lack of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000f5da0-d6d3-11e7-802c-bf2be12a889d</td>\n",
       "      <td>DECLASSIFIED\\nAuthority AND TaTas\\nCi\\nINCOMIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00101db0-da04-11e7-9df5-3f82820eb790</td>\n",
       "      <td>DECLASSIFIED\\nAuthority NND 75I9\\nJULY 28 1948...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid  \\\n",
       "0  0003c4f0-d60f-11e7-b559-3b0450bb4b8f   \n",
       "1  0007f860-df8b-11e7-9dda-8be1c775c1be   \n",
       "2  000bfbf0-d607-11e7-839a-3da120885759   \n",
       "3  000f5da0-d6d3-11e7-802c-bf2be12a889d   \n",
       "4  00101db0-da04-11e7-9df5-3f82820eb790   \n",
       "\n",
       "                                            ocr_text  \n",
       "0                          DECLASSIFIED\\nAuthority\\n  \n",
       "1  National Advisory Council\\nStDocument No. 236\\...  \n",
       "2  DECLASSIFIED\\nAuthority. escal-\\nthe lack of s...  \n",
       "3  DECLASSIFIED\\nAuthority AND TaTas\\nCi\\nINCOMIN...  \n",
       "4  DECLASSIFIED\\nAuthority NND 75I9\\nJULY 28 1948...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ocr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>ocr_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003c4f0-d60f-11e7-b559-3b0450bb4b8f</td>\n",
       "      <td>DECLASSIFIED Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0007f860-df8b-11e7-9dda-8be1c775c1be</td>\n",
       "      <td>National Advisory Council StDocument No. 236 e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000bfbf0-d607-11e7-839a-3da120885759</td>\n",
       "      <td>DECLASSIFIED Authority. escal- the lack of soy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000f5da0-d6d3-11e7-802c-bf2be12a889d</td>\n",
       "      <td>DECLASSIFIED Authority AND TaTas Ci INCOMING I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00101db0-da04-11e7-9df5-3f82820eb790</td>\n",
       "      <td>DECLASSIFIED Authority NND 75I9 JULY 28 1948 a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid  \\\n",
       "0  0003c4f0-d60f-11e7-b559-3b0450bb4b8f   \n",
       "1  0007f860-df8b-11e7-9dda-8be1c775c1be   \n",
       "2  000bfbf0-d607-11e7-839a-3da120885759   \n",
       "3  000f5da0-d6d3-11e7-802c-bf2be12a889d   \n",
       "4  00101db0-da04-11e7-9df5-3f82820eb790   \n",
       "\n",
       "                                            ocr_text  \n",
       "0                            DECLASSIFIED Authority   \n",
       "1  National Advisory Council StDocument No. 236 e...  \n",
       "2  DECLASSIFIED Authority. escal- the lack of soy...  \n",
       "3  DECLASSIFIED Authority AND TaTas Ci INCOMING I...  \n",
       "4  DECLASSIFIED Authority NND 75I9 JULY 28 1948 a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## remove \\n\n",
    "test = df_ocr.copy()\n",
    "test['ocr_text'] = test.ocr_text.map(lambda s: s.replace('\\n',' '))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz',binary=True)\n",
    "words = model.index2word\n",
    "w_rank = {}\n",
    "for i, word in enumerate(words):\n",
    "    w_rank[word] = i\n",
    "WORDS_vec = w_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORDS_big = Counter(words(open('data/big.txt').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORDS = WORDS_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## spelling correction\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    \"To reduce computational load, skip the number/known word/one character\"\n",
    "    if re.search(r'\\d+',word): \n",
    "        return word\n",
    "#     elif len(word) == 1:\n",
    "#         return word\n",
    "#     elif len(known([word])) == 0 : \n",
    "#         return word\n",
    "    else:\n",
    "        return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_text = list(map(correction,words(test.ocr_text[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document stdocument\n",
      "end endix\n",
      "however howevor\n",
      "moreover morcover\n",
      "hung tung\n",
      "hung tung\n",
      "five fivo\n",
      "human hunan\n",
      "hope hupeh\n",
      "choking chekiang\n",
      "order ordor\n",
      "hung tung\n",
      "marketing markcting\n",
      "upon hupoh\n",
      "the tho\n",
      "present presont\n",
      "earn earni\n",
      "nos ngs\n",
      "hung tung\n",
      "assumed assuned\n",
      "concealing canceling\n",
      "earnings carnings\n",
      "hung tung\n",
      "valued valucd\n",
      "united unitod\n",
      "hung tung\n",
      "reach roach\n",
      "quantities quantitios\n",
      "synthesis synthetic\n",
      "linseed linsced\n",
      "hung tung\n",
      "us usc\n",
      "points paints\n",
      "vanishes varnishes\n",
      "reasons roasons\n",
      "united unitod\n",
      "hung tung\n",
      "even evon\n",
      "merit metric\n",
      "export oxport\n",
      "hung tung\n",
      "the tho\n",
      "bristled bristles\n",
      "bristled bristles\n",
      "source sourco\n",
      "estimated estinatod\n",
      "equivalent cquivalent\n",
      "were repre\n",
      "sensitive sentative\n",
      "your yoar\n",
      "years ycars\n",
      "bristled bristles\n",
      "being boing\n",
      "long hong\n",
      "long kong\n",
      "classified declassified\n",
      "and nnd\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_text)):\n",
    "    if test_text[i]!=words(test.ocr_text[1])[i]:\n",
    "        print (test_text[i],words(test.ocr_text[1])[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "for w in test_text:\n",
    "    text = text.join(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ''.join(test_text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLASSIFIED'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction('DECLASSIFIED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## extract date\n",
    "def extract_date(text):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:NLP]",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
